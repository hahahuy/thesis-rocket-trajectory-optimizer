# Data Directory

- raw/: per-case HDF5/NPZ files generated by WP3
- processed/: consolidated train/val/test datasets

Generate data:

```bash
bash scripts/gen_data.sh
```

Preprocess + splits:

```bash
bash scripts/make_splits.sh
```
# Processed Dataset Snapshot

Generated by `scripts/inspect_processed_data.py`.

## Train Split
- File: `data\processed\train.h5`
- Cases: **120**
- Time steps per case: **1501**
- Context dimension: **7**
- State tensor shape (cases × time × 14): `[120, 1501, 14]`
- Context fields (7): `m0`, `Isp`, `Cd`, `CL_alpha`, `Cm_alpha`, `Tmax`, `wind_mag`
- Scaling (excerpt):
  - L: 10000.0
  - V: 313.0
  - T: 31.62
  - M: 50.0
  - F: 490.0
  - W: 0.0316

## Val Split
- File: `data\processed\val.h5`
- Cases: **20**
- Time steps per case: **1501**
- Context dimension: **7**
- State tensor shape (cases × time × 14): `[20, 1501, 14]`
- Context fields (7): `m0`, `Isp`, `Cd`, `CL_alpha`, `Cm_alpha`, `Tmax`, `wind_mag`
- Scaling (excerpt):
  - L: 10000.0
  - V: 313.0
  - T: 31.62
  - M: 50.0
  - F: 490.0
  - W: 0.0316

## Test Split
- File: `data\processed\test.h5`
- Cases: **20**
- Time steps per case: **1501**
- Context dimension: **7**
- State tensor shape (cases × time × 14): `[20, 1501, 14]`
- Context fields (7): `m0`, `Isp`, `Cd`, `CL_alpha`, `Cm_alpha`, `Tmax`, `wind_mag`
- Scaling (excerpt):
  - L: 10000.0
  - V: 313.0
  - T: 31.62
  - M: 50.0
  - F: 490.0
  - W: 0.0316

