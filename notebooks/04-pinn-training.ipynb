{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# WP4 - PINN Training Demo\n",
        "\n",
        "This notebook demonstrates training and evaluating a Physics-Informed Neural Network (PINN) for 6-DOF rocket trajectory prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import yaml\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path().resolve().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "sys.path.insert(0, str(project_root / 'src'))\n",
        "\n",
        "from src.models import PINN\n",
        "from src.utils.loaders import create_dataloaders\n",
        "from src.data.preprocess import load_scales, Scales\n",
        "from src.eval.visualize_pinn import (\n",
        "    evaluate_model,\n",
        "    plot_trajectory_comparison,\n",
        "    plot_loss_curves\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data and Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load configuration\n",
        "config_path = project_root / 'configs' / 'train.yaml'\n",
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# Load scales\n",
        "scales_path = project_root / 'configs' / 'scales.yaml'\n",
        "scales_dict = load_scales(str(scales_path))\n",
        "scales = Scales(**scales_dict)\n",
        "\n",
        "# Create dataloaders\n",
        "data_dir = project_root / 'data' / 'processed'\n",
        "train_loader, val_loader, test_loader = create_dataloaders(\n",
        "    data_dir=str(data_dir),\n",
        "    batch_size=8,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "print(f\"Train cases: {len(train_loader.dataset)}\")\n",
        "print(f\"Val cases: {len(val_loader.dataset)}\")\n",
        "print(f\"Test cases: {len(test_loader.dataset)}\")\n",
        "print(f\"Context dimension: {train_loader.dataset.context_dim}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model configuration\n",
        "model_cfg = config.get('model', {})\n",
        "context_dim = train_loader.dataset.context_dim\n",
        "\n",
        "model = PINN(\n",
        "    context_dim=context_dim,\n",
        "    n_hidden=model_cfg.get('n_hidden', 6),\n",
        "    n_neurons=model_cfg.get('n_neurons', 128),\n",
        "    activation=model_cfg.get('activation', 'tanh'),\n",
        "    fourier_features=model_cfg.get('fourier_features', 8),\n",
        "    layer_norm=model_cfg.get('layer_norm', True),\n",
        "    dropout=model_cfg.get('dropout', 0.05)\n",
        ")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"Device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Trained Model (or Train)\n",
        "\n",
        "To train a model, use:\n",
        "```bash\n",
        "./scripts/train_pinn.sh --config configs/train.yaml\n",
        "```\n",
        "\n",
        "Here we'll load a checkpoint if available, otherwise show how to train.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Try to load checkpoint\n",
        "checkpoint_path = project_root / 'experiments' / 'pinn_baseline' / 'checkpoints' / 'best.pt'\n",
        "\n",
        "if checkpoint_path.exists():\n",
        "    print(f\"Loading checkpoint from {checkpoint_path}\")\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"Loaded model from epoch {checkpoint['epoch']}\")\n",
        "    print(f\"Validation loss: {checkpoint['loss']:.6f}\")\n",
        "else:\n",
        "    print(\"No checkpoint found. Run training first:\")\n",
        "    print(\"  ./scripts/train_pinn.sh --config configs/train.yaml\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on test set\n",
        "model.eval()\n",
        "metrics = evaluate_model(model, test_loader, device, scales)\n",
        "\n",
        "print(\"Test Set Metrics:\")\n",
        "print(f\"  Total RMSE: {metrics['rmse_total']:.6f}\")\n",
        "print(\"\\nPer-component RMSE:\")\n",
        "for name, rmse in metrics['rmse_per_component'].items():\n",
        "    print(f\"  {name}: {rmse:.6f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Sample Trajectories\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot sample trajectories\n",
        "fig_dir = project_root / 'experiments' / 'pinn_baseline' / 'figures'\n",
        "fig_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, batch in enumerate(test_loader):\n",
        "        if i >= 3:  # Plot first 3 cases\n",
        "            break\n",
        "        \n",
        "        t = batch['t'].to(device)\n",
        "        context = batch['context'].to(device)\n",
        "        state_true = batch['state'].to(device)\n",
        "        \n",
        "        if t.dim() == 2:\n",
        "            t = t.unsqueeze(-1)\n",
        "        \n",
        "        state_pred = model(t, context)\n",
        "        \n",
        "        # Convert to numpy\n",
        "        t_np = t[0].cpu().squeeze(-1).numpy()\n",
        "        pred_np = state_pred[0].cpu().numpy()\n",
        "        true_np = state_true[0].cpu().numpy()\n",
        "        \n",
        "        plot_trajectory_comparison(\n",
        "            t_np, pred_np, true_np, scales,\n",
        "            save_path=str(fig_dir / f'trajectory_case_{i}.png'),\n",
        "            title=f'Case {i}'\n",
        "        )\n",
        "        \n",
        "        print(f\"Saved trajectory plot for case {i}\")\n",
        "\n",
        "print(f\"\\nFigures saved to: {fig_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Training Curves\n",
        "\n",
        "If training log is available, plot loss curves.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load training log\n",
        "import json\n",
        "\n",
        "log_path = project_root / 'experiments' / 'pinn_baseline' / 'train_log.json'\n",
        "\n",
        "if log_path.exists():\n",
        "    with open(log_path, 'r') as f:\n",
        "        train_log = json.load(f)\n",
        "    \n",
        "    plot_loss_curves(\n",
        "        train_log,\n",
        "        save_path=str(fig_dir / 'loss_curves.png')\n",
        "    )\n",
        "    print(\"Loss curves saved\")\n",
        "else:\n",
        "    print(\"Training log not found. Run training first.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
