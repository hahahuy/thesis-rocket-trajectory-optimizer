loss:
  homotopy_schedule: fixed
  lambda_bc: 1.0
  lambda_data: 1.0
  lambda_phys: 0.1
  lambda_phys_final: 1.0
model:
  context_embedding_dim: 64
  d_model: 128
  dim_feedforward: 512
  dropout: 0.05
  fourier_features: 8
  n_heads: 4
  n_layers: 2
  transformer_activation: gelu
  type: sequence
physics_config: configs/phys.yaml
scales_config: configs/scales.yaml
train:
  batch_size: 8
  early_stopping_min_delta: 0.0
  early_stopping_patience: 10
  epochs: 100
  experiment_name: sequence_full
  learning_rate: 1e-3
  num_workers: 0
  scheduler:
    kwargs:
      T_max: 100
      eta_min: 1e-6
    type: cosine
  time_subsample: null
  weight_decay: 1e-5
