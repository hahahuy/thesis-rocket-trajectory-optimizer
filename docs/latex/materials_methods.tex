% Materials and Methods chapter for the thesis on physics-informed surrogate modelling
% for rocket ascent trajectory dynamics. This file is intended to be included from
% the main thesis document.

\chapter{Materials and Methods}

\section{Overview of the Methodological Workflow}

The methodology was organized around three sequential stages. First, a physical
model of six-degree-of-freedom (6-DOF) rocket dynamics was formulated and
implemented numerically. Second, optimal control trajectories were generated
using direct collocation methods and used to construct training datasets. Third,
physics-informed neural network (PINN) surrogates were trained on these datasets
to approximate the dynamics. The relationship between the optimal control solver,
truth integrator, and PINN surrogate is illustrated schematically in
Figure~\ref{fig:Relationship_OTP_PINN}.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=14.5cm]{figures/RelaOTP.pdf}
    \caption{Schematic diagram illustrating the relationship between the optimal 
    control solver, truth integrator, and PINN surrogate in the methodological workflow.}
    \label{fig:Relationship_OTP_PINN}
\end{figure}

\section{Rocket Dynamics Model}

\subsection{Reference Frames and Coordinate Systems}

Two primary reference frames were used. The inertial frame was defined as
Earth-centred and non-rotating, with the \(z\)-axis pointing upward (opposite to
gravity). The body frame was defined as vehicle-fixed, with the \(x\)-axis aligned
with the nominal thrust direction. Transformations between frames were
represented using unit quaternions.

The state vector \(\mathbf{x}(t) \in \mathbb{R}^{14}\) was defined as
\[
  \mathbf{x}(t) =
  \begin{bmatrix}
    \mathbf{r}_\mathrm{i}^\top &
    \mathbf{v}_\mathrm{i}^\top &
    \mathbf{q}^\top &
    \boldsymbol{\omega}_\mathrm{b}^\top &
    m
  \end{bmatrix}^\top ,
\]
where \(\mathbf{r}_\mathrm{i} \in \mathbb{R}^3\) was the position in the inertial
frame, \(\mathbf{v}_\mathrm{i} \in \mathbb{R}^3\) was the inertial velocity,
\(\mathbf{q} = [q_0, q_1, q_2, q_3]^\top\) was a unit quaternion representing the
attitude (body-to-inertial rotation), \(\boldsymbol{\omega}_\mathrm{b} \in
\mathbb{R}^3\) was the angular velocity expressed in the body frame, and \(m \in
\mathbb{R}\) was the mass of the vehicle.

The control vector \(\mathbf{u}(t) \in \mathbb{R}^4\) was defined as
\[
  \mathbf{u}(t) =
  \begin{bmatrix}
    T &
    \theta_\mathrm{g} &
    \phi_\mathrm{g} &
    \delta
  \end{bmatrix}^\top ,
\]
where \(T\) was the commanded thrust magnitude, \(\theta_\mathrm{g}\) and
\(\phi_\mathrm{g}\) were the thrust gimbal pitch and yaw angles, and \(\delta\) was a
representative control surface deflection.

The body-to-inertial rotation matrix
\(R_{\mathrm{b}\to\mathrm{i}}(\mathbf{q})\) was obtained from the quaternion
\(\mathbf{q}\). Its transpose \(R_{\mathrm{i}\to\mathrm{b}} =
R_{\mathrm{b}\to\mathrm{i}}^\top\) transformed vectors from the inertial frame to
the body frame.

\subsection{Equations of Motion}

The translational motion was governed by Newton's second law:
\[
  \dot{\mathbf{r}}_\mathrm{i} = \mathbf{v}_\mathrm{i}, \qquad
  \dot{\mathbf{v}}_\mathrm{i} =
  \frac{1}{m}\,\mathbf{F}_\mathrm{i}(\cdot) + \mathbf{g}_\mathrm{i}(\mathbf{r}_\mathrm{i}),
\]
where \(\mathbf{F}_\mathrm{i}\) was the total non-gravitational force in the
inertial frame and \(\mathbf{g}_\mathrm{i}\) was the gravitational acceleration.
A constant gravitational field \(\mathbf{g}_\mathrm{i} = [0, 0, -g_0]^\top\) was
employed, where \(g_0 = 9.81\) m/s\(^2\) was the nominal surface gravity.

Rotational dynamics were expressed as
\[
  \dot{\mathbf{q}} =
    \tfrac{1}{2}\,\mathbf{q} \otimes
    \begin{bmatrix}0 \\ \boldsymbol{\omega}_\mathrm{b}\end{bmatrix},
  \qquad
  \dot{\boldsymbol{\omega}}_\mathrm{b}
    = \mathbf{I}_\mathrm{b}^{-1}
      \Bigl(
        \mathbf{M}_\mathrm{b} -
        \boldsymbol{\omega}_\mathrm{b} \times
        (\mathbf{I}_\mathrm{b}\boldsymbol{\omega}_\mathrm{b})
      \Bigr),
\]
where \(\mathbf{I}_\mathrm{b}\) was the inertia tensor in the body frame and
\(\mathbf{M}_\mathrm{b}\) was the sum of aerodynamic and thrust moments.

The mass dynamics followed the standard rocket equation~\cite{sutton2017}:
\[
  \dot{m} = -\frac{T}{I_\mathrm{sp} g_0},
\]
with specific impulse \(I_\mathrm{sp}\) and surface gravity \(g_0\). A dry-mass
limit was enforced in the implementation to prevent unphysical mass depletion.

These equations follow standard formulations for rigid-body rocket dynamics~\cite{bryson1975,betts2010}.

\subsection{Aerodynamic and Propulsion Models}

The atmosphere was modelled by an exponential density profile:
\[
  \rho(h) = \rho_0 \exp\!\left(-\frac{h}{h_\mathrm{scale}}\right),
\]
where \(h\) was altitude above sea level, \(\rho_0 = 1.225\) kg/m\(^3\) was the
sea-level density, and \(h_\mathrm{scale} = 8400\) m was a scale height. The
dynamic pressure was computed as
\[
  q_\mathrm{dyn} = \frac{1}{2}\,\rho(h)\,\|\mathbf{v}_\mathrm{rel,b}\|^2,
\]
where \(\mathbf{v}_\mathrm{rel,b}\) was the relative wind velocity in the body
frame.

Aerodynamic forces were naturally expressed in the body frame. The relative wind
velocity was computed as
\[
  \mathbf{v}_\mathrm{rel,i} = \mathbf{v}_\mathrm{i} - \mathbf{v}_\mathrm{wind,i},
  \qquad
  \mathbf{v}_\mathrm{rel,b} =
  R_{\mathrm{i}\to\mathrm{b}}(\mathbf{q})\,\mathbf{v}_\mathrm{rel,i},
\]
where \(\mathbf{v}_\mathrm{wind,i}\) was the wind velocity in the inertial frame.
Wind disturbances were neglected, so \(\mathbf{v}_\mathrm{wind,i} = \mathbf{0}\).

Drag and lift forces in the body frame took the form
\[
  \mathbf{F}_\mathrm{D,b}
    = - q_\mathrm{dyn} S_\mathrm{ref} C_\mathrm{D}\,\hat{\mathbf{v}}_\mathrm{rel,b},
  \qquad
  \mathbf{F}_\mathrm{L,b}
    = q_\mathrm{dyn} S_\mathrm{ref} C_{\mathrm{L}\alpha}\,\alpha\,
      \hat{\mathbf{e}}_\mathrm{L},
\]
where \(S_\mathrm{ref}\) was a reference area, \(C_\mathrm{D}\) was the drag
coefficient, \(C_{\mathrm{L}\alpha}\) was a lift-curve slope, \(\alpha\) was the
angle of attack computed from \(\mathbf{v}_\mathrm{rel,b}\), and
\(\hat{\mathbf{e}}_\mathrm{L}\) was a unit lift direction approximately
perpendicular to the body \(x\)-axis and the relative velocity.

The thrust vector in the body frame was
\[
  \mathbf{u}_T =
  \begin{bmatrix}
    \cos\theta_\mathrm{g}\cos\phi_\mathrm{g} \\
    \sin\phi_\mathrm{g} \\
    \sin\theta_\mathrm{g}\cos\phi_\mathrm{g}
  \end{bmatrix},
  \qquad
  \mathbf{F}_\mathrm{T,b} = T\,\frac{\mathbf{u}_T}{\|\mathbf{u}_T\|},
\]
so that the total non-gravitational force in the body frame was
\[
  \mathbf{F}_\mathrm{b} =
  \mathbf{F}_\mathrm{T,b} +
  \mathbf{F}_\mathrm{D,b} +
  \mathbf{F}_\mathrm{L,b},
  \qquad
  \mathbf{F}_\mathrm{i} =
  R_{\mathrm{b}\to\mathrm{i}}(\mathbf{q})\,\mathbf{F}_\mathrm{b}.
\]

\section{Numerical Trajectory Generation via Optimal Control}

\subsection{Optimal Control Problem Formulation}

Numerically optimal ascent trajectories were generated by solving a constrained 
optimal control problem (OCP), The OCP was discretised using a direct collocation
method based on the Hermiteâ€“Simpson scheme~\cite{betts2010,ross2004}. Which served 
as a data-generation mechanism for training and evaluating the physics-informed 
surrogate model. The OCP was formulated as a continuous-time optimal control problem 
over a finite horizon \(t \in [0, t_f]\), with the 6-DOF dynamics as constraints. 
The objective function was formulated to minimise fuel consumption, subject to path 
and terminal constraints on altitude, velocity, attitude, and structural loads. The 
time horizon was fixed at \(t_f = 30\) s.

The control vector \(\mathbf{u}(t) \in \mathbb{R}^4\) was defined as
\[
  \mathbf{u}(t) =
  \begin{bmatrix}
    T &
    \theta_\mathrm{g} &
    \phi_\mathrm{g} &
    \delta
  \end{bmatrix}^\top ,
\]
with bounds on thrust magnitude \(T \in [0, T_\mathrm{max}]\), gimbal angles
\(\theta_\mathrm{g}, \phi_\mathrm{g} \in [-\theta_\mathrm{max},
\theta_\mathrm{max}]\), and control surface deflection \(\delta \in
[-\delta_\mathrm{max}, \delta_\mathrm{max}]\). Path constraints enforced maximum
dynamic pressure \(q_\mathrm{dyn} \leq q_\mathrm{dyn,max}\) and maximum load
factor \(n \leq n_\mathrm{max}\).

The OCP was discretised using a direct collocation method. The continuous state
and control trajectories were approximated on a uniform grid of nodes
\(\{t_k\}_{k=0}^N\) with step size \(h = t_f/N\). At each node, the state
\(x_k \approx x(t_k)\) and control \(u_k \approx u(t_k)\) became decision
variables in a finite-dimensional nonlinear programme (NLP). The dynamics were
enforced via Hermite--Simpson collocation, which provided third-order accuracy
by introducing a collocation point at the midpoint of each interval and enforcing
a defect constraint of the form
\[
  x_{k+1}
  = x_k + \frac{h}{6}
    \bigl(
      f(x_k, u_k) + 4 f(x_m, u_m) + f(x_{k+1}, u_{k+1})
    \bigr),
\]
where \(f(x,u)\) denotes the state derivative, \(x_m\) is a midpoint state
constructed from \((x_k,x_{k+1})\) and \((f(x_k,u_k), f(x_{k+1},u_{k+1}))\), and
\(u_m\) is the midpoint control. The resulting collocation defects were enforced
as equality constraints in the NLP.

\subsection{Numerical Solvers and Software}

The 6-DOF dynamics, including aerodynamics, thrust, and mass depletion, were
implemented symbolically in CasADi. This provided exact Jacobians and Hessians to
the NLP solver, which was crucial for robustness and performance in the presence
of stiff dynamics and tight path constraints. Special care was taken in the
implementation to avoid non-differentiabilities and division by small quantities,
for example by using smooth norm approximations and explicit clamping of mass
and thrust.

\noindent CasADi version 3.6.7 and IPOPT version 3.14.16 were used in all 
numerical optimization experiments, with linear solver backends selected 
automatically based on availability.

The discretised OCP was solved using IPOPT, a large-scale interior-point
nonlinear optimiser. State and control variables were scaled using reference
length, velocity, time, mass, and force scales for conditioning, and
linear solver backends (such as MUMPS or HSL variants) were selected
automatically depending on availability. The framework supported both fixed and
free final time, with appropriate bounds on \(t_f\) when treated as a decision
variable.

Path constraints on dynamic pressure \(q_\mathrm{dyn}\), load factor \(n\), and
mass were enforced directly in the NLP using auxiliary CasADi functions for these
quantities. Operational limits on gimbal angles, control-surface deflections,
and angle of attack were also encoded in the state and control bounds.

In addition to the collocation-based OCP solver, a high-fidelity C++
integrator for the same 6-DOF dynamics was implemented and used as a truth
model for validation and data generation. This integrator supported
inverse-square gravity, exponential atmosphere, aerodynamic forces and moments,
wind callbacks, and detailed diagnostic outputs such as dynamic pressure, load
factor, and constraint violations.

For data-driven approximation, a differentiable version of the dynamics and the 
physics-informed neural network models were implemented using PyTorch~\cite{paszke2019} 
version 2.x (or LibTorch 2.3.1 as an C++ frontend for PyTorch). 
This module mirrored the CasADi model, including the state and control definitions, 
aerodynamic coefficients, and mass dynamics, but used tensor operations to enable automatic differentiation.

The time discretization was fixed at \(N = 1501\) points, corresponding to a
30-second flight duration sampled at 50 Hz.

\section{Dataset Construction and Preprocessing}

\subsection{Dataset Structure}

The data pipeline produced a hierarchy of datasets. At the lowest level, raw cases
were stored as individual HDF5 files containing time grids, full 14-D state
trajectories, control histories, monitor signals (e.g., dynamic pressure and load
factor), and rich metadata including physical parameters, solver statistics, and
configuration hashes. These raw cases were then aggregated into processed split
files (train/validation/test) in nondimensional form. 

The processed datasets contained approximately 120 training cases, 20 validation
cases, and 20 test cases. Each trajectory was discretised on a uniform time
grid with \(N = 1501\) points, corresponding to a 30-second flight duration
sampled at 50 Hz. Each processed dataset exposed a time grid, a context vector
\(\mathbf{c} \in \mathbb{R}^7\) encoding key physical and environmental
parameters (initial mass \(m_0\), specific impulse \(I_\mathrm{sp}\), drag
coefficient \(C_\mathrm{D}\), lift-curve slope \(C_{\mathrm{L}\alpha}\),
pitch-moment coefficient \(C_{\mathrm{m}\alpha}\), maximum thrust
\(T_\mathrm{max}\), and wind magnitude), and normalised state targets.

The state tensor shape was \(\text{state} \in \mathbb{R}^{N_\mathrm{cases}
\times N_\mathrm{time} \times 14}\), where \(N_\mathrm{cases}\) is the number
of trajectories, \(N_\mathrm{time} = 1501\) is the number of time points, and
14 is the state dimension.

\subsection{Nondimensionalization and Scaling}

All state and control variables were nondimensionalized using physics-aware
reference scales for numerical conditioning and intended to be scale-invariant
learning. The reference scales were chosen to yield quantities of order unity,
as summarized in Table~\ref{tab:reference-scales-mm}.

\begin{table}[h]
\centering
\caption{Reference scales for nondimensionalization}
\label{tab:reference-scales-mm}
\begin{tabular}{llll}
\toprule
Quantity & Symbol & Value & Motivation \\
\midrule
Length & \(L_\mathrm{ref}\) & 10,000 m & Typical altitude \\
Velocity & \(V_\mathrm{ref}\) & 313 m/s & \(\sqrt{g_0 L_\mathrm{ref}}\) \\
Time & \(T_\mathrm{ref}\) & 31.62 s & \(L_\mathrm{ref}/V_\mathrm{ref}\) \\
Mass & \(M_\mathrm{ref}\) & 50 kg & Nominal wet mass \\
Force & \(F_\mathrm{ref}\) & 490 N & \(M_\mathrm{ref} g_0\) \\
\bottomrule
\end{tabular}
\end{table}

The scaling equation was
\[
  \tilde{x} = \frac{x}{x_\mathrm{ref}},
\]
where \(\tilde{x}\) is the nondimensionalized quantity and \(x_\mathrm{ref}\) is the
corresponding reference scale. This nondimensionalization ensured that all state
components were typically in the range \([0.1, 10]\), which improved gradient
flow during neural network training and reduced numerical errors in the
optimization solver. The scaling was inverted during evaluation to recover
dimensional quantities. This nondimensionalization follows standard practice 
in numerical simulation for conditioning and training stability~\cite{anderson1995}.

\section{Physics-Informed Neural Network Model}

\subsection{Model Inputs and Outputs}

The model inputs were time \(t\) (a scalar) and a context vector
\(\mathbf{c} \in \mathbb{R}^7\) encoding physical and environmental parameters.
The model output was the state vector \(\mathbf{x}(t) \in \mathbb{R}^{14}\).

\subsection{Network Architecture (Direction AN)}

The Direction AN architecture was organized into three stages (see
Figure~\ref{fig:direction_an_diagram}). A shared stem first embedded the
normalised time and context: time was expanded and encoded by Fourier features 
embedding~\cite{tancik2020} 
with 8 frequencies, while the context vector was passed through a small encoder (a
shallow multilayer perceptron) and then concatenated with the time embedding.
This combined input was processed by a residual multilayer perceptron with 4
layers, hidden dimension 128, skip connections, tanh activation, and layer
normalization, yielding a latent feature sequence \(z(t, c)\) of fixed dimension
along the trajectory.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=12cm]{figures/direction_an_diagram.pdf}
  \caption{Architecture of the Direction AN model. The shared stem processes
  architecture of the Direction AN model. The shared stem processes
  time and context inputs to produce a latent representation \(z(t, c)\). Three
  specialized branches (translation, rotation, mass) map this latent space to
  the corresponding state components. The physics residual layer computes
  dynamics residuals to enforce physical consistency.}
  \label{fig:direction_an_diagram}
\end{figure}

On top of this shared latent representation, three mission branches specialized
to different parts of the 14-D state. A translation branch with hidden dimensions
\([128, 128]\) mapped \(z\) to position and velocity components
\([\mathbf{r}_\mathrm{i}, \mathbf{v}_\mathrm{i}]\). A rotation branch with hidden
dimensions \([256, 256]\) mapped \(z\) to quaternion and angular velocity
components \([\mathbf{q}, \boldsymbol{\omega}_\mathrm{b}]\) with explicit
quaternion renormalization. A mass branch with hidden dimension \([64]\)
produced the mass trajectory \(m(t)\). The concatenation of these branch outputs
formed the predicted state \(x_\theta(t)\).

\subsection{Physics Residual Computation}

Although control inputs were explicitly modeled in the optimal control formulation
used for data generation, the trained physics-informed neural network surrogate 
did not take control variables as direct inputs. Consequently, control terms 
were omitted from the physics residual during training, and the surrogate 
learned the state evolution implicitly from the resulting state trajectories. 
This design choice was adopted in order to evaluate the ability of the surrogate to reproduce 
ascent dynamics without explicit control conditioning.

The physics residual was computed using finite difference derivative
approximations, rather than automatic differentiation. For interior points, a
central difference scheme was used:
\[
  \frac{dx}{dt} \approx \frac{x_{i+1} - x_{i-1}}{2\Delta t},
\]
where \(\Delta t = 0.02\) s is the time step (corresponding to 50 Hz sampling).
For boundary points, forward difference (first point) and backward difference
(last point) schemes were used.

In the PINN setting, explicit control inputs were omitted and set to zero in the
physics residual, reflecting the design choice that the network learned state
evolution implicitly from trajectories rather than from control commands. The
control \(\mathbf{u}_k\) in the physics loss was therefore set to zero
(\(\mathbf{u}_k = [0, 0, 0, 0]^\top\)). This zero-control assumption was
consistent with the processed dataset format, which did not include control
trajectories.

\subsection{Architecture Selection Procedure}

The final Direction AN architecture was obtained through a structured model selection 
process. Several candidate architectures were evaluated to assess the impact of 
architectural choices on training stability, physical consistency, and trajectory 
reconstruction accuracy.

In particular, variants differing in the handling of temporal inputs, mission 
parameters, and output coupling were examined. Architectures combining time and 
context inputs at a single shallow layer were evaluated and not retained due to 
unstable convergence behavior and sensitivity to scaling. In contrast, architectures 
employing separate encoders for temporal inputs and mission parameters, followed by 
a shared latent representation, showed improved convergence behavior and more 
stable physics residuals. These architectures were retained for further evaluation.

Additionally, separating the output into distinct heads for translational states, rotational states, 
and mass evolution was evaluated and found to facilitate loss balancing and improve interpretability of individual 
error components. Based on these observations, a shared-stem architecture with specialized output branches 
was selected as the final Direction AN configuration, as illustrated 
in Figure~\ref{fig:ArchitectureSelection}.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=14.2cm]{figures/ArchitectureSelection.pdf}
  \caption{Model selection process for the Direction AN architecture. 
  Summarizes the selection process used to refine the network architecture. 
  Architectural choices were guided by observed training stability, 
  sensitivity to input scaling, and the ability to balance heterogeneous 
  loss components, rather than by exhaustive hyperparameter search.}
  \label{fig:ArchitectureSelection}
\end{figure}

\section{Training Procedure}

\subsection{Loss Function Definition}

The total training loss was constructed as a weighted combination of multiple 
terms enforcing data fidelity, physical consistency, and structural constraints. 
Rather than relying on a single objective, the loss function was designed to reflect 
different aspects of the rocket ascent dynamics following standard physics-informed 
learning formulations~\cite{raissi2019}.

The primary loss components were grouped into four categories:
\begin{enumerate}
  \item Data fidelity losses, which penalized deviations between predicted and 
  reference state trajectories obtained from numerical simulation.
  \item Physics consistency losses, which penalized violations of the governing equations 
  of motion, including translational dynamics, rotational kinematics, and mass depletion.
  \item Structural constraint losses, which enforced properties intrinsic to the system 
  representation, such as unit-norm quaternion constraints and monotonic mass depletion.
  \item Regularization losses, which promoted smoothness of the predicted trajectories 
  and suppressed high-frequency numerical artifacts.

\end{enumerate}

The data loss \(L_\mathrm{data}\) was a component-weighted mean-squared error
between predicted and true states, with separate group weights for translation,
rotation, and mass:
\[
  L_\mathrm{data} = \lambda_\mathrm{translation} L_\mathrm{translation} +
  \lambda_\mathrm{rotation} L_\mathrm{rotation} +
  \lambda_\mathrm{mass} L_\mathrm{mass},
\]
where \(\lambda_\mathrm{translation} = 1.0\), \(\lambda_\mathrm{rotation} =
1.0\), and \(\lambda_\mathrm{mass} = 1.0\) were the group weights, and
\(L_\mathrm{translation}\), \(L_\mathrm{rotation}\), and \(L_\mathrm{mass}\) were
component-weighted MSE losses for the respective state groups.

The physics loss \(L_\mathrm{phys}\) penalised violations of the continuous
dynamics by comparing a finite-difference estimate of the time derivative
\(\dot{x}_\theta(t_k)\) to the right-hand side \(f(x_\theta(t_k), \mathbf{u}_k =
\mathbf{0}; \mathbf{p})\) of the 6-DOF model implemented in PyTorch:
\[
  L_\mathrm{phys}
  = \frac{1}{N} \sum_{k=0}^{N-1}
    \bigl\|
      \dot{x}_\theta(t_k) - f(x_\theta(t_k), \mathbf{u}_k = \mathbf{0}; \mathbf{p})
    \bigr\|^2 .
\]

A boundary term \(L_\mathrm{bc}\) enforced agreement between predicted and true
initial conditions:
\[
  L_\mathrm{bc} = \|\mathbf{x}_\theta(0) - \mathbf{x}^\star(0)\|^2.
\]

Additional loss terms were included to suppress non-physical lateral drift, enforce 
smooth ascent behavior, and stabilize training by penalizing high-frequency 
numerical artifacts, particularly during the early ascent phase. These loss terms are:
\begin{itemize}
  \item \(L_\mathrm{mass,res}\): Mass residual loss ensuring mass decreases
        monotonically
  \item \(L_\mathrm{vz,res}\): Vertical velocity residual loss
  \item \(L_\mathrm{vxy,res}\): Horizontal velocity residual loss
  \item \(L_\mathrm{smooth,z}\): Temporal smoothing for altitude
  \item \(L_\mathrm{smooth,vz}\): Temporal smoothing for vertical velocity
  \item \(L_\mathrm{pos,vel}\): Position--velocity consistency loss
  \item \(L_\mathrm{smooth,pos}\): Position smoothing loss
  \item \(L_\mathrm{zero,vxy}\): Zero horizontal velocity loss
  \item \(L_\mathrm{zero,axy}\): Zero horizontal acceleration loss
  \item \(L_\mathrm{hacc}\): Horizontal acceleration constraint loss
  \item \(L_\mathrm{xy,zero}\): Zero horizontal position loss
\end{itemize}

The total loss was
\begin{equation}
\begin{split}
  \mathcal{L} &= \lambda_\mathrm{data} L_\mathrm{data} +
  \lambda_\mathrm{phys} L_\mathrm{phys} +
  \lambda_\mathrm{bc} L_\mathrm{bc} \\
  &\quad + \lambda_\mathrm{mass,res} L_\mathrm{mass,res} +
  \lambda_\mathrm{vz,res} L_\mathrm{vz,res} +
  \lambda_\mathrm{vxy,res} L_\mathrm{vxy,res} \\
  &\quad + \lambda_\mathrm{smooth,z} L_\mathrm{smooth,z} +
  \lambda_\mathrm{smooth,vz} L_\mathrm{smooth,vz} +
  \lambda_\mathrm{pos,vel} L_\mathrm{pos,vel} \\
  &\quad + \lambda_\mathrm{smooth,pos} L_\mathrm{smooth,pos} +
  \lambda_\mathrm{zero,vxy} L_\mathrm{zero,vxy} +
  \lambda_\mathrm{zero,axy} L_\mathrm{zero,axy} \\
  &\quad + \lambda_\mathrm{hacc} L_\mathrm{hacc} +
  \lambda_\mathrm{xy,zero} L_\mathrm{xy,zero},
\end{split}
\end{equation}
where the loss weights were set to \(\lambda_\mathrm{data} = 1.0\),
\(\lambda_\mathrm{phys} = 0.1\), \(\lambda_\mathrm{bc} = 1.0\),
\(\lambda_\mathrm{mass,res} = 0.05\), \(\lambda_\mathrm{vz,res} = 0.05\),
\(\lambda_\mathrm{vxy,res} = 0.01\), \(\lambda_\mathrm{smooth,z} = 5.0 \times
10^{-4}\), \(\lambda_\mathrm{smooth,vz} = 1.0 \times 10^{-4}\),
\(\lambda_\mathrm{pos,vel} = 1.0\), \(\lambda_\mathrm{smooth,pos} = 2.0 \times
10^{-3}\), \(\lambda_\mathrm{zero,vxy} = 1.0\), \(\lambda_\mathrm{zero,axy} =
1.0\), \(\lambda_\mathrm{hacc} = 0.02\), and \(\lambda_\mathrm{xy,zero} = 5.0\).

\subsection{Optimization and Training Schedule}

The network was trained using the Adam optimizer~\cite{kingma2015} with learning rate \(1.0 \times
10^{-3}\), weight decay \(1.0 \times 10^{-5}\), and batch size 8. Training was
conducted for 160 epochs. A cosine annealing learning rate scheduler~\cite{loshchilov2017} was used
with \(T_\mathrm{max} = 160\) and minimum learning rate \(\eta_\mathrm{min} = 1.0
\times 10^{-6}\).

A phased training schedule was employed where loss weights were adjusted over
time. In the initial phase (approximately the first 55\% of training epochs),
the model focused on fitting the data and coarse physics constraints, with
lower weights on higher-order regularization terms. In the second phase, these
regularization weights were gradually increased using a cosine ramp schedule~\cite{loshchilov2017},
which was designed to gradually increase the regularization weights over time, designing like this 
to allow the model to refine its predictions while maintaining physical
consistency. This phased training schedule was designed to help the model refine 
its predictions while maintaining physical consistency.

Early stopping was implemented with patience 25 for phase 1 and patience 40 for
phase 2, with minimum delta 0.0. This early stopping was designed to prevent the 
model from overfitting to the regularization terms early in training while ensuring that physical
constraints are properly enforced in the final model.


\subsection{Evaluation Metrics}

Model performance was evaluated using root mean square error (RMSE) computed on
the test set. For a trained Direction AN model, predictions
\(\hat{\mathbf{x}}_\theta(t_k)\) were generated for all test trajectories on a
uniform time grid \(\{t_k\}_{k=0}^{N-1}\) spanning the trajectory duration
(30 seconds). The total RMSE was computed as
\[
  \mathrm{RMSE}_\mathrm{total} = \sqrt{\frac{1}{B \cdot N \cdot D} \sum_{b=1}^{B}
  \sum_{k=0}^{N-1} \sum_{d=1}^{D} \left(\hat{x}_\theta^{(b)}(t_k)_d - 
  x^{\star(b)}(t_k)_d\right)^2},
\]
where \(B = 20\) was the number of test trajectories, \(N = 1501\) was the number
of time points in the discretized trajectory grid (corresponding to a sampling
rate of approximately 50 Hz), \(D = 14\) was the state dimension, and
\(x^{\star(b)}(t_k)\) denoted the ground truth state for trajectory \(b\) at time
\(t_k\). The summation over \(k\) from \(0\) to \(N-1\) averaged the squared
errors across all time points in each trajectory, while the summation over \(b\)
averaged across all test trajectories, and the summation over \(d\) averaged across
all state components.

Per-component RMSE was computed by averaging over trajectories and time points
for each state dimension \(d\), while aggregated metrics were computed for
translation (components 1--6: position and velocity), rotation (components
7--13: quaternion and angular velocity), and mass (component 14). All RMSE values
were reported in nondimensional units, reflecting the scaled state
representation used during training.

\subsection{Loss Weight Selection and Sensitivity Analysis}

The relative weighting of loss components was selected using a combination of 
physical reasoning and empirical sensitivity analysis. Initial loss weights were 
chosen based on the expected physical significance and numerical scale of each state 
component, informed by exploratory analysis of the trajectory data. For example, 
altitude, vertical velocity, and mass evolution were assigned higher relative 
importance due to their dominant role in ascent performance.

To refine these initial choices, coarse parameter sweeps were conducted to identify 
ranges of loss weights that yielded stable training and physically plausible trajectories. 
Within these ranges, a lightweight evolutionary search procedure was employed to test local 
variations of loss weights and assess their effect on convergence behavior and validation 
error. This process was used to improve robustness rather than to identify a globally optimal 
configuration, as illustrated in Figure~\ref{fig:LossWeightSelection}.

The final loss weights were selected based on a balance between data fidelity, physical consistency, 
and training stability, and were fixed for all reported experiments.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=14.5cm]{figures/LossWeightSelection.pdf}
  \caption{Loss weight selection process. The selection of loss weights followed a structured 
  procedure summarized, combining physical intuition, sensitivity analysis, and local evolutionary 
  refinement to ensure stable and interpretable training.}
  \label{fig:LossWeightSelection}
\end{figure}

\subsection{Implementation Details}

The optimal control solver was implemented using CasADi for symbolic computation 
and IPOPT for nonlinear optimization. The truth integrator was implemented in C++. 
Random seeds were fixed for all experiments to ensure reproducibility. Data 
processing and training scripts were written in Python, using NumPy for numerical 
operations and HDF5 for data storage. The neural network models were implemented 
in PyTorch. Training was performed on a workstation with automatic device selection 
depending on availability. (CPU or GPU if available), and no hardware-specific 
optimizations were employed. This implementation was designed to be reproducible 
and scalable.

\subsection{Summary of Chapter}

A six-degree-of-freedom rocket dynamics model was formulated and implemented at
three fidelity levels: a high-fidelity C++ truth integrator, a symbolic CasADi
version for optimal control, and a differentiable PyTorch implementation for
PINN training. Optimal control trajectories were generated using direct
collocation with Hermite--Simpson discretization and solved using IPOPT. These
trajectories were used to construct training datasets with 120 training cases, 20
validation cases, and 20 test cases, each discretized on a uniform time grid
with 1501 points over 30 seconds. A physics-informed neural network architecture
(Direction AN) was designed with a shared stem, three specialized branches for
translation, rotation, and mass, and a physics residual layer. The network was
trained using a phased schedule with Adam optimization, incorporating data
fidelity, physics consistency, structural constraints, and smoothing
regularization terms in the loss function.

